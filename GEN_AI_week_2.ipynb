{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokeCoder11/KnowledgeReference/blob/main/GEN_AI_week_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0888cfe4",
      "metadata": {
        "id": "0888cfe4"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import cos_sim\n",
        "\n",
        "sentences = ['That is a happy person', 'That is a very happy person and he like to eat burger']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf9d1ba",
      "metadata": {
        "id": "5bf9d1ba"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5', trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d962428",
      "metadata": {
        "id": "2d962428"
      },
      "outputs": [],
      "source": [
        "sentences = ['That is a happy person', 'That is a very happy person and he like to eat burger']\n",
        "#               0                                 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f5532c",
      "metadata": {
        "id": "71f5532c",
        "outputId": "7bcce38e-c1b9-4b10-f9dc-1ed8f1825c5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.23888129, -0.14091976, -0.22524117, ...,  0.15000696,\n",
              "        0.06842457, -0.5583947 ], dtype=float32)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.encode(sentences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2202cba8",
      "metadata": {
        "id": "2202cba8",
        "outputId": "046ac0f5-8f48-4547-a5e9-29258718b4b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.6057478 ,  0.8114514 , -0.10117444, ...,  0.4886877 ,\n",
              "        0.2710827 , -0.5948143 ], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.encode(sentences[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0632e553",
      "metadata": {
        "id": "0632e553",
        "outputId": "eaa4a29d-9ac1-42ea-9d8e-5f7b4273351d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.encode(sentences[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c84de6",
      "metadata": {
        "id": "65c84de6",
        "outputId": "ab4e95d8-68c1-44bb-b6ab-a1504708c3b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.encode(sentences[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862465ce",
      "metadata": {
        "id": "862465ce",
        "outputId": "28c42dfe-ef8a-4680-8f18-f41fa73d49ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.encode(sentences[0]).ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41fbcfd",
      "metadata": {
        "id": "f41fbcfd"
      },
      "outputs": [],
      "source": [
        "# import the existing word and sentence tokenizing\n",
        "# libraries\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af91a93",
      "metadata": {
        "id": "3af91a93"
      },
      "outputs": [],
      "source": [
        "text = \"Natural language processing (NLP) is a field\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0998bc59",
      "metadata": {
        "id": "0998bc59",
        "outputId": "74e7c2c0-9ac1-4817-8f25-5947a9a63f8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3259710",
      "metadata": {
        "id": "d3259710",
        "outputId": "906d05b7-3cae-46c6-b93b-cb3c73c389e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Natural language processing (NLP) is a field Hi how are you']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Natural language processing (NLP) is a field Hi how are you\"\n",
        "sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04353d7",
      "metadata": {
        "id": "e04353d7"
      },
      "source": [
        "1) LM - question Anwering\n",
        "2) Deployment of any LM proposal project on basic web app - Gradio (python)\n",
        "3) LLM application  - RAG\n",
        "4) complete end to end application\n",
        "5) Doubts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68f32ea7",
      "metadata": {
        "id": "68f32ea7",
        "outputId": "50856e6e-1541-47ee-f53d-880001b796f4",
        "colab": {
          "referenced_widgets": [
            "ea3edc37d7674ac6830a01aac71be390",
            "ea9fb9da81be453b934ed58700e17686",
            "817d8795de43428b985ee36053328b90",
            "91d4c583324a42e7886272a8a8cdf77b",
            "9e131525c6914c4a89efa181bba3971f",
            "58f9f5eb2a5a47e1bb3bbd89c7d0c575"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3edc37d7674ac6830a01aac71be390",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--timpal0l--mdeberta-v3-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea9fb9da81be453b934ed58700e17686",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "817d8795de43428b985ee36053328b90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91d4c583324a42e7886272a8a8cdf77b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e131525c6914c4a89efa181bba3971f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58f9f5eb2a5a47e1bb3bbd89c7d0c575",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4977d4",
      "metadata": {
        "id": "ba4977d4"
      },
      "outputs": [],
      "source": [
        "context = \"My name is Tim and I live in Sweden.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9876a85e",
      "metadata": {
        "id": "9876a85e",
        "outputId": "f80a0c57-0ae7-452e-aae2-c8287b43a8cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.9755483269691467, 'start': 28, 'end': 36, 'answer': ' Sweden.'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"Where do I live?\"\n",
        "qa_model(question = question, context = context)\n",
        "# {'score': 0.975547730922699, 'start': 28, 'end': 36, 'answer': ' Sweden.'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b87403",
      "metadata": {
        "id": "c7b87403"
      },
      "outputs": [],
      "source": [
        "#!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda532df",
      "metadata": {
        "id": "eda532df"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "def hello_greet(inp):\n",
        "    return \"hello how are \"+\"---\"+inp\n",
        "demo = gr.Interface(fn=hello_greet,inputs='text',outputs='text')\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6892723d",
      "metadata": {
        "id": "6892723d",
        "outputId": "02ba1af5-ab7a-4cbf-9143-c76856f6375e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7863\n",
            "Running on public URL: https://ba649dbeba67430e9c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ba649dbeba67430e9c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7bb954",
      "metadata": {
        "id": "cc7bb954",
        "outputId": "e045320d-e964-4e9b-a712-3ac1d8428ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7867\n",
            "Running on public URL: https://0c17004a36fba3773c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0c17004a36fba3773c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "qa_model = pipeline(\"question-answering\", \"timpal0l/mdeberta-v3-base-squad2\")\n",
        "def hello_greet(question,q2):\n",
        "    context = \"My name is Tim and I live in Sweden.\"\n",
        "    ans = qa_model(question = question, context = q2)\n",
        "    return ans[\"answer\"]\n",
        "demo = gr.Interface(fn=hello_greet,inputs=['text','text'],outputs='text')\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72bbc86b",
      "metadata": {
        "id": "72bbc86b"
      },
      "source": [
        "![image-3.png](attachment:image-3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de06750",
      "metadata": {
        "id": "5de06750"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "932eeb2a",
      "metadata": {
        "id": "932eeb2a"
      },
      "outputs": [],
      "source": [
        "\"hi how are you I am good how are you?\"\n",
        "s1 = \"hi how are you\"\n",
        "s2 = \"are you I am\"\n",
        "s3 =\"I am good how\"\n",
        "s4 = \"good how are you\"\n",
        "\n",
        "s1 =\"hi how are you\"\n",
        "s2 = \"I am good how are\"\n",
        "s3 = \"?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678b136d",
      "metadata": {
        "id": "678b136d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd2f2c9",
      "metadata": {
        "id": "cfd2f2c9"
      },
      "outputs": [],
      "source": [
        "# Document Loading\n",
        "\n",
        "## Retrieval augmented generation\n",
        "\n",
        "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
        "\n",
        "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc).\n",
        "\n",
        "![overview.jpeg](attachment:overview.jpeg)\n",
        "\n",
        "#! pip install langchain\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "# connector\n",
        "import langchain\n",
        "from langchain import   OpenAI\n",
        "from langchain import document_loaders\n",
        "print(dir(OpenAI))\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
        "pages = loader.load()\n",
        "\n",
        "pages[0]\n",
        "\n",
        "from langchain import text_splitter\n",
        "print(dir(text_splitter))\n",
        "\n",
        "import langchain\n",
        "from langchain.text_splitter import CharacterTextSplitter,TokenTextSplitter,RecursiveCharacterTextSplitter\n",
        "\n",
        "#?CharacterTextSplitter\n",
        "?RecursiveCharacterTextSplitter\n",
        "\n",
        "s1 = \"India got independence in 1947 and Now its 2024 India is 5 largest econm\"\n",
        "\n",
        "# character :\"I\", \"n\", \"d\"\n",
        "\n",
        "s1 = \"awsedrftgyhjghjklsxrdctgbh\"\n",
        "\n",
        "text_spl = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=10,\n",
        "    chunk_overlap=2)\n",
        "\n",
        "text_spl.split_text(s1)\n",
        "\n",
        "pip install -qU langchain-ai21\n",
        "\n",
        "import openai\n",
        "\n",
        "from openai import Embedding\n",
        "print(dir(Embedding))\n",
        "\n",
        "?Embedding ( Model)\n",
        "\n",
        "# steps to overcome such problem\n",
        "\n",
        "import langchain\n",
        "from langchain.embeddings.openai import   OpenAIEmbeddings\n",
        "emd_model = OpenAIEmbeddings()\n",
        "\n",
        "doc = '''Sachin Tendulkar, (/ˌsʌtʃɪn tɛnˈduːlkər/ ⓘ; pronounced [sətɕin teːɳɖulkəɾ]; born 24 April 1973) is an Indian former international cricketer who captained the Indian national team. He is widely regarded as one of the greatest batsmen in the history of cricket.[4] Hailed as the world's most prolific batsman of all time, he is the all-time highest run-scorer in both ODI and Test cricket with more than 18,000 runs and 15,000 runs, respectively.[5] He also holds the record for receiving the most player of the match awards in international cricket.[6] Tendulkar was a Member of Parliament, Rajya Sabha by nomination from 2012 to 2018.[7][8]\n",
        "\n",
        "Tendulkar took up cricket at the age of eleven, made his Test match debut on 15 November 1989 against Pakistan in Karachi at the age of sixteen, and went on to represent Mumbai domestically and India internationally for over 24 years.[9] In 2002, halfway through his career, Wisden ranked him the second-greatest Test batsman of all time, behind Don Bradman, and the second-greatest ODI batsman of all time, behind Viv Richards.[10] The same year, Tendulkar was a part of the team that was one of the joint-winners of the 2002 ICC Champions Trophy. Later in his career, Tendulkar was part of the Indian team that won the 2011 Cricket World Cup, his first win in six World Cup appearances for India.[11] He had previously been named \"Player of the Tournament\" at the 2003 World Cup.\n",
        "\n",
        "Tendulkar has received several awards from the government of India: the Arjuna Award (1994), the Khel Ratna Award (1997), the Padma Shri (1998), and the Padma Vibhushan (2008).[12][13] After Tendulkar played his last match in November 2013, the Prime Minister's Office announced the decision to award him the Bharat Ratna, India's highest civilian award.[14][15] He was the first sportsperson to receive the reward and, as of 2023, is the youngest recipient.[16][17][18] In 2010, Time included Tendulkar in its annual list of the most influential people in the world.[19] Tendulkar was awarded the Sir Garfield Sobers Trophy for cricketer of the year at the 2010 International Cricket Council (ICC) Awards.[20]'''\n",
        "text_spl = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=10,\n",
        "    chunk_overlap=2)\n",
        "text_split = text_spl.split_text(doc)\n",
        "text_split\n",
        "emd_list = []\n",
        "for i in text_split:\n",
        "    emd_list.append(emd_model.aembed_query(i))\n",
        "\n",
        "len(text_split), len(emd_list)\n",
        "\n",
        "# croma DB\n",
        "\n",
        "# challenges  -\n",
        "1) Structure of input data\n",
        "2) Statement what croma DB takes\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "location = 'docs/chroma/'\n",
        "\n",
        "!rm -rf ./docs/chroma\n",
        "\n",
        "vdb = Chroma.from_texts(texts = text_split,\n",
        "                       embedding =emd_model,\n",
        "                       persist_directory = 'docs/chroma/')\n",
        "# it will only run for those case - from doc where you have PDF, document\n",
        "\n",
        "vdb.similarity_search(query=\"india\")\n",
        "\n",
        "# LLM - Reterival Chain\n",
        "\n",
        "\n",
        "\n",
        "# Memory\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dbe26f1",
      "metadata": {
        "id": "3dbe26f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99b83947",
      "metadata": {
        "id": "99b83947"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}